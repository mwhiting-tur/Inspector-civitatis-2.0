name: Ejecutar Scraping Manual

on:
  workflow_dispatch: 

jobs:
  run-scraper:
    # Forzamos 22.04 que es la versión más estable para Playwright
    runs-on: ubuntu-22.04 
    
    steps:
      - name: Descargar código del repo
        uses: actions/checkout@v4

      - name: Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Instalar dependencias de Python
        run: |
          python -m pip install --upgrade pip
          pip install playwright pandas
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Instalar Navegador y Dependencias de Sistema
        run: |
          # Usar 'python -m' asegura que encuentre Playwright donde se instaló
          python -m playwright install chromium --with-deps

      - name: Ejecutar el script de scraping
        run: python main.py 

      - name: Guardar cambios (CSV/Excel)
        # ESTO ES LO MÁS IMPORTANTE:
        # Se ejecutará aunque el paso anterior haya fallado o dado timeout.
        if: always() 
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add data/*.csv
          git commit -m "Snapshot parcial de datos (en caso de error)" || exit 0
          git push